data: celeb
mode: latent
ckpt: weights/gaf_dit_sd15_celeba_256_1152_28_16_p2_ckpt_ema_it0100000.pt

gen_dir: gen/gaf_celeba256_gen

num_train_classes: None

# Mode: precompute vs train
precompute: false

# Device / IO
device: "cuda"
seed: 0    
outdir: "./runs/gaf_dit_sd15_celeba_256_1152_28_16_p2_oneclass_1K_v1"
log_every: 500

# Data or Latents path
data_path: "./celeba_hq_256"
image_size: 256
encode_batch_size: 128
latent_cache: "./celeba256_sd15_mean_bf16_latents_determnistic_bicubic.pt"
resume_path: "./runs/gaf_dit_sd15_celeba_256_1152_28_16_p2_oneclass_1K_v1/final_state.pt"
num_classes: 1

# VAE
"vae_model": "stabilityai/sd-vae-ft-mse"
vae_scale: 0.18215

# Model (DiT)
latent_ch: 4
dit_hidden: 1152
dit_depth: 28
dit_heads: 16
patch_size: 2
mlp_ratio: 4.0

# Train Hyperparameters
batch: 32
accum_steps: 1
workers: 4
iters: 100000
lr: 1.0e-4
warmup_steps: 3000
betas: [0.9, 0.99]
weight_decay: 0.0
grad_clip: 0.0

# Runtime / Optimization
bf16: true
channels_last: true
pin_memory: true
non_blocking: true
compile: true

# Loss / time sampling
t_eps: 1.0e-3
res_reg: 0.003
lam_time: 0.002

# EMA
use_ema: true
ema_decay_warm: 0.999
ema_decay_main: 0.9999
ema_decay_steps: 5000

# Sampling / preview
preview_every: 1000
checkpoint_every: 50000
preview_nfe: 20       
preview_chunk: 4
preview_H: 256
preview_W: 256

# W&B
use_wandb: true
wandb_project: "GAF-CELEBA"
wandb_run_name: "H200-CELEBA-VectorizedExp"
wandb_tags: ["H200", "CELEBA", "VectorizedExp"]